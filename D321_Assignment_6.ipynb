{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import all the required packages in this cell"
      ],
      "metadata": {
        "id": "IHU8YKriCK-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STARTER CODE: D-321 Data Preprocessing Evaluation Assignment\n",
        "# NOTE: This code assumes the 'generate_missingness_datasets.py' script has been\n",
        "# run and all required CSV files and 'metadata.json' are in 'generated_datasets/'.\n",
        "# ==============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json"
      ],
      "metadata": {
        "id": "fw76FGrDagoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions, metadata and logging"
      ],
      "metadata": {
        "id": "kLmu_7XYC6OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset_from_metadata(file_meta):\n",
        "    \"\"\"\n",
        "    Loads a specific dataset CSV using its metadata dictionary.\n",
        "\n",
        "    Parameters:\n",
        "        file_meta (dict): Dictionary containing file path information (key 'file')\n",
        "                          and dataset type (key 'dataset').\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            - X (pd.DataFrame): Feature matrix.\n",
        "            - y (pd.Series): Target vector (named '__target__').\n",
        "            - task_type (str): 'classification' or 'regression'.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the target column '__target__' is not found.\n",
        "    \"\"\"\n",
        "    file_path = f\"{dataset_dir}/{file_meta['file']}\"\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    if '__target__' not in df.columns:\n",
        "        raise ValueError(f\"Target column '__target__' not found in {file_meta['file']}\")\n",
        "\n",
        "    X = df.drop(columns=['__target__'])\n",
        "    y = df['__target__']\n",
        "\n",
        "    dname = file_meta['dataset']\n",
        "    task_type = 'classification' if dname in ['breast_cancer', 'wine', 'synthetic_clf'] else 'regression'\n",
        "\n",
        "    return X, y, task_type\n",
        "\n",
        "\n",
        "def log_results(dataset, task, m_type, m_percent, impute_tech, encoder_tech, scaler_tech,\n",
        "                model_name, fold, seed, metric_name, metric_value):\n",
        "    \"\"\"\n",
        "    Appends the results of a single experiment run to the global results_log DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "        dataset (str): Name of the base dataset (e.g., 'breast_cancer').\n",
        "        task (str): Type of evaluation task ('intrinsic' or 'extrinsic').\n",
        "        m_type (str): Missingness mechanism ('MCAR', 'MAR', 'MNAR', or 'CLEAN').\n",
        "        m_percent (float): Percentage of missing values (0.0, 10.0, 30.0, etc.).\n",
        "        impute_tech (str): Imputation technique used.\n",
        "        encoder_tech (str): Encoder technique used.\n",
        "        scaler_tech (str): Scaler technique used.\n",
        "        model_name (str): Model family used ('RandomForest', 'Logistic', 'NN', etc.).\n",
        "        fold (int): Cross-validation fold index.\n",
        "        seed (int): Random seed used for missingness generation or CV.\n",
        "        metric_name (str): The name of the performance metric (e.g., 'Accuracy', 'RMSE').\n",
        "        metric_value (float): The calculated value of the performance metric.\n",
        "\n",
        "    Outputs:\n",
        "        (None): Appends a row to the global results_log DataFrame.\n",
        "    \"\"\"\n",
        "    global results_log\n",
        "    new_row = {\n",
        "        'dataset': dataset, 'task': task, 'missingness_type': m_type,\n",
        "        'missing_percent': m_percent, 'imputation_technique': impute_tech,\n",
        "        'encoder_technique': encoder_tech, 'scaler_technique': scaler_tech,\n",
        "        'model': model_name, 'fold': fold, 'seed': seed,\n",
        "        'metric_name': metric_name, 'metric_value': metric_value\n",
        "    }\n",
        "    results_log = pd.concat([results_log, pd.Series(new_row).to_frame().T], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "huIDrHJlC_4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeCg4JwPZ4tT"
      },
      "outputs": [],
      "source": [
        "dataset_dir = \"generated_datasets\" # path to datasets\n",
        "metadata_path = f\"{dataset_dir}/metadata.json\" # path to metadata.json\n",
        "N_SPLITS = 5 # For cross-validation\n",
        "\n",
        "# DataFrame to store all experiment results\n",
        "results_log = pd.DataFrame(columns=[\n",
        "    'dataset', 'task', 'missingness_type', 'missing_percent',\n",
        "    'imputation_technique', 'encoder_technique', 'scaler_technique',\n",
        "    'model', 'fold', 'seed', 'metric_name', 'metric_value'\n",
        "])\n",
        "\n",
        "# Load metadata to map file names to experimental parameters\n",
        "try:\n",
        "    with open(metadata_path, 'r') as f:\n",
        "        METADATA = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Metadata file not found at {metadata_path}. Please ensure the generation script has been run.\")\n",
        "    METADATA = []"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1. Implementation of Imputation/Encoding and Scaling Methods\n",
        "\n",
        "1. Numeric imputation: drop attribute (column removal), mean (numeric only), median\n",
        "(numeric/ordinal), mode, Last Observation Carried Forward imputation (LOCF, only if\n",
        "time-series or grouped; otherwise explain limitations), linear interpolation. (10 marks)\n",
        "2. Categorical encoders: Label, one-hot, binary, target encoding with out-of-fold (OOF) safe\n",
        "scheme. Provide an OOF implementation or use category encoders with OOF. (10 marks)\n",
        "3. Scaling/normalization: min-max, z-score, log (handle zeros), box-cox / yeo-johnson, quan-\n",
        "tile, sigmoid, max-abs, unit-length. (5 marks)"
      ],
      "metadata": {
        "id": "J5jr9S1_CdUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Task 1: Implementation Guide\n",
        "\n",
        "You should replace the placeholder comments with the correct initialized Scikit-learn\n",
        "or category_encoders classes.\n",
        "\n",
        "For custom methods (LOCF, Linear Interpolation, Log, Sigmoid), ensure the implementations fit them into\n",
        "the Pipeline structure.\n",
        "\n",
        "Using raw Pandas functions (.fillna(method='ffill')) without wrapping them breaks the scikit-learn framework.\n",
        "\"\"\"\n",
        "NUMERIC_IMPUTERS = {\n",
        "    'drop_col': 'drop_col',\n",
        "    'mean': # TODO: Replace with proper implementation\n",
        "    'median': # TODO: Replace with proper implementation\n",
        "    'mode': # TODO: Replace with proper implementation\n",
        "    'locf': # TODO: Replace with proper implementation\n",
        "    'linear_interp': # TODO: Replace with proper implementation\n",
        "}\n",
        "\n",
        "CATEGORICAL_ENCODERS = {\n",
        "    'label': # TODO: Replace with proper implementation\n",
        "    'one_hot': # TODO: Replace with proper implementation\n",
        "    'binary': # TODO: Replace with proper implementation\n",
        "    'target_oof':  # TODO: Implement OOF Target Encoder\n",
        "}\n",
        "\n",
        "SCALERS = {\n",
        "    'min_max': # Implement min-max scaler\n",
        "    'z_score': # Implement z-score scaler\n",
        "    'log':  # TODO: Implement Log with zero handling\n",
        "    'box_cox_yeo_johnson':  # TODO: Replace with proper implementation\n",
        "    'quantile':  # TODO: Replace with proper implementation\n",
        "    'sigmoid':  # TODO: Replace with proper implementation\n",
        "    'max_abs':  # TODO: Replace with proper implementation\n",
        "    'unit':  # TODO: Replace with proper implementation\n",
        "}"
      ],
      "metadata": {
        "id": "jggIn4CcamKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_preprocessor(numeric_features, categorical_features, impute_tech, encoder_tech, scaler_tech):\n",
        "    \"\"\"\n",
        "    Builds the ColumnTransformer for the preprocessing pipeline based on\n",
        "    the current experiment's configuration.\n",
        "\n",
        "    Parameters:\n",
        "        numeric_features (list): List of column names that are numeric.\n",
        "        categorical_features (list): List of column names that are categorical.\n",
        "        impute_tech (str): The chosen numeric imputation technique key (e.g., 'mean', 'drop_col').\n",
        "        encoder_tech (str): The chosen categorical encoder technique key (e.g., 'one_hot', 'none').\n",
        "        scaler_tech (str): The chosen scaling technique key (e.g., 'min_max', 'none').\n",
        "\n",
        "    Returns:\n",
        "        ColumnTransformer: A scikit-learn ColumnTransformer object ready to be\n",
        "                           integrated into a Pipeline.\n",
        "    \"\"\"\n",
        "\n",
        "    # Numeric Pipeline: TODO include all the preprocessing to be applied to numerical columns\n",
        "\n",
        "\n",
        "    # Categorical Pipeline: TODO include all the preprocessing to be applied to categorical coluns\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "HmQrQ68qgFoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2. Experiment Pipeline & Evaluation Functions\n",
        "\n",
        "1. Missing value imputation evaluation: For each dataset with missing values, \\\n",
        "-- Evaluate intrinsic imputation quality (RMSE for numeric; accuracy for categorical) by\n",
        "masking a separate holdout of observed values. (8 marks) \\\n",
        "-- Evaluate extrinsic model performance (Classification: Accuracy + ROC-AUC; Regres-\n",
        "sion: RMSE + R²) using three model families: Random Forest, Logistic/Linear (with\n",
        "regularization), and Neural Networks(NN), against the testing dataset. (12 marks)  \\\n",
        "-- Scaling/normalization: min-max, z-score, log (handle zeros), box-cox / yeo-johnson,\n",
        "quantile, sigmoid, max-abs, unit-length. (5 marks)\n",
        "2. Category encoder evaluation: For each original training dataset, evaluate extrinsic model\n",
        "performance (Classification: Accuracy + ROC-AUC; Regression: RMSE + R²) using three\n",
        "model families: Random Forest, Logistic/Linear (with regularization), and NN, against the\n",
        "testing dataset. (12 marks)\n",
        "3. Log results (in CSV) including dataset name, missingness, technique, model, fold, seed,\n",
        "metric. (5 marks)"
      ],
      "metadata": {
        "id": "MGuU0XRwD2TW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Task 2: Model Implementation Guide\n",
        "\n",
        "You should initialize the appropriate Scikit-learn model classes.\n",
        "\n",
        "Crucial Reminder for Consistency and Reproducibility:\n",
        "- For models that use randomness (RandomForest, MLPClassifier/Regressor),\n",
        "  the 'random_state' parameter MUST be set to ensure results are repeatable.\n",
        "- For iterative models (LogisticRegression, MLP), set a sufficiently high\n",
        "  'max_iter' (e.g., 500-1000) to ensure convergence across different datasets.\n",
        "\"\"\"\n",
        "MODELS = {\n",
        "    'classification': {\n",
        "        'RandomForest':  # TODO: Replace with proper implementation\n",
        "        'Logistic':  # TODO: Replace with proper implementation\n",
        "        'NN':  # TODO: Replace with proper implementation\n",
        "    },\n",
        "    'regression': {\n",
        "        'RandomForest': # TODO: Replace with proper implementation\n",
        "        'Linear':  # TODO: Replace with proper implementation\n",
        "        'NN':  # TODO: Replace with proper implementation\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "HvTFz0kCEU2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_imputation_intrinsic(X_train_miss, X_train_full, dname, m_type, m_percent, seed):\n",
        "    \"\"\"\n",
        "    Task 2: Intrinsic Imputation Quality Evaluation\n",
        "\n",
        "    Compares the imputed values against the known true values (original observed\n",
        "    values that were intentionally masked for this evaluation).\n",
        "\n",
        "    Parameters:\n",
        "        X_train_miss (pd.DataFrame): Training features with the assignment-defined missing values.\n",
        "        X_train_full (pd.DataFrame): The original, complete training features (ground truth).\n",
        "        dname (str): Base dataset name.\n",
        "        m_type (str): Missingness mechanism (e.g., 'MCAR').\n",
        "        m_percent (float): Missing value percentage.\n",
        "        seed (int): Random seed used for missing value generation.\n",
        "\n",
        "    TODO:\n",
        "        1. Create a **separate intrinsic evaluation mask** on the observed values of X_train_miss.\n",
        "        2. Introduce temporary NaNs based on this mask.\n",
        "        3. Loop through all **NUMERIC_IMPUTERS**.\n",
        "        4. Apply the imputer and calculate **RMSE** between imputed values and X_train_full (ground truth).\n",
        "        5. Log the results using `log_results` with `task='intrinsic'`.\n",
        "    \"\"\"\n",
        "    print(f\"--- TODO: Implementing Intrinsic Imputation Quality for {dname} ({m_type} {m_percent}%) ---\")\n",
        "    pass\n",
        "\n",
        "\n",
        "def run_extrinsic_evaluation(X_train, y_train, X_test, y_test, file_meta,\n",
        "                             impute_tech='none', encoder_tech='none', scaler_tech='none'):\n",
        "    \"\"\"\n",
        "    Task 2: Extrinsic Model Performance Evaluation\n",
        "\n",
        "    Performs cross-validation on the X_train set to fit the full preprocessing\n",
        "    pipeline and model, and then evaluates the final pipeline on the external\n",
        "    X_test holdout set. This ensures no data leakage.\n",
        "\n",
        "    Parameters:\n",
        "        X_train (pd.DataFrame): Training features (potentially with missing values).\n",
        "        y_train (pd.Series): Training target.\n",
        "        X_test (pd.DataFrame): External testing features (always clean/full).\n",
        "        y_test (pd.Series): External testing target.\n",
        "        file_meta (dict): Metadata dictionary for logging experiment details.\n",
        "        impute_tech (str): Imputation technique being tested/used.\n",
        "        encoder_tech (str): Encoder technique being tested/used.\n",
        "        scaler_tech (str): Scaler technique being tested/used.\n",
        "\n",
        "    Outputs:\n",
        "        (None): Logs results to the global results_log DataFrame for each model and fold.\n",
        "    \"\"\"\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "TOAfzzRIgK5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_experiment_loop():\n",
        "    \"\"\"\n",
        "    Main function to orchestrate the entire experiment by loading pre-generated\n",
        "    files and running all required evaluation tasks (A & B).\n",
        "\n",
        "    The main loop ensures that:\n",
        "        1. A consistent 80/20 Train/Test split is used for all experiments.\n",
        "        2. Experiments are run across all defined preprocessing configurations.\n",
        "        3. Results are logged to 'results.csv'.\n",
        "    \"\"\"\n",
        "    if not METADATA:\n",
        "        return\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # A. TODO: Task 2 -> Missing Value Imputation Evaluation\n",
        "    # ----------------------------------------------------------------------\n",
        "        # Load the pre-generated training set with missingness\n",
        "\n",
        "        # Retrieve the consistent 20% test set and original clean training set\n",
        "\n",
        "        # 1. Intrinsic evaluation (Task 2)\n",
        "\n",
        "        # 2. Extrinsic evaluation (Task 2)\n",
        "\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # B. TODO: Task 2 -> Category Encoder and Scaling Evaluation (on CLEAN data)\n",
        "    # ----------------------------------------------------------------------\n",
        "      # 1. Category Encoder Evaluation\n",
        "      # 2. Scaling/Normalization Evaluation\n",
        "\n",
        "\n",
        "    # Save results (Task 2 - Log results)\n",
        "\n"
      ],
      "metadata": {
        "id": "JsjLT3lvgS9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_experiment_loop()"
      ],
      "metadata": {
        "id": "-r15Srnm_yNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3. Visualizations\n",
        "\n",
        "1. Compare imputation methods across missingness & datasets & model. (7 marks)\n",
        "2. Compare category encoding methods across datasets and models. (7 marks)\n",
        "3. Compare scaling/normalization methods across datasets and models. (7 marks)\n",
        "4. Summarize key findings: which techniques are robust, interactions with model type, surpris-\n",
        "ing results. (7 marks)"
      ],
      "metadata": {
        "id": "LaCo1go9BlJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Include all the visualizations below"
      ],
      "metadata": {
        "id": "xUWitj50BiAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-0TgTETQCA2v"
      }
    }
  ]
}